# Text Style Transfer Config
defaults:
  - base_tst
  - _self_
# Data
dataset: yelp
dataset_seed: null
direction: 0_to_1
# Reward
style_tokenizer: "bert-base-uncased"
lower_outputs: true
control_output_length: true
# Single Prompt Model
prompt_length: 2
prompt_train_batch_size: 8
prompt_infer_batch_size: 16
# LM Adaptor Model
logit_bias: -10
# SQL Module
reward_shaping_old_min: 0
reward_shaping_old_max: 1
reward_shaping_new_min: -20
reward_shaping_new_max: 80
top_k: 50
# Trainer
train_batch_size: 2
num_repeats: 4
max_train_steps: 12000
train_shuffle: false
eval_batch_size: 16
eval_steps: 50
save_steps: 100
learning_rate: 5e-5
random_seed: null
# new settings
report_to_wandb: false
training_device: "cpu"
run_name: null 
dpo_loss_config: 
  dpo_training: false
  name: "dpo"
  beta: 0.5
  reference_free: false
  label_smoothing: 0.0
  reference_learning_rate: 0.001
  multi_optimize: false
task_lm: distilgpt2
